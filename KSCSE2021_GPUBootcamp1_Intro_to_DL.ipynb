{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KSCSE2021_GPUBootcamp1_Intro_to_DL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# KSCSE2021 GPU Bootcamp AI for Science\n",
        "by Hyun Gon Ryu | NVAITC Korea\n"
      ],
      "metadata": {
        "id": "LF7sXcD5AG-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Primer and Keras 101"
      ],
      "metadata": {
        "id": "I_ZUAZ5W82LL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "bkT9aEI_5_Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Necessary Libraries\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(\"Tensorflow version : \", tf.__version__)\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "#tf.debugging.set_log_device_placement(True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DARQqYlc6qn7",
        "outputId": "90c5c9d6-f293-490e-efcb-bde0c028de78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version :  2.7.0\n",
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's Import the Dataset\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "8dmPHWzXAqly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset returns four NumPy arrays:\n",
        "\n",
        "* The `train_images` and `train_labels` arrays are the *training set*—the data the model uses to learn.\n",
        "* The model is tested against the *test set*, the `test_images`, and `test_labels` arrays.\n",
        "\n",
        "The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of clothing the image represents:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Each image is mapped to a single label. Since the *class names* are not included with the dataset, let us store them in an array so that we can use them later when plotting the images:"
      ],
      "metadata": {
        "id": "LimONzEHAycI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "metadata": {
        "id": "zxkt-CiyAqo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding the Data"
      ],
      "metadata": {
        "id": "HnwjbnbHBBjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print Array Size of Training Set \n",
        "print(\"Size of Training Images :\"+str(train_images.shape))\n",
        "#Print Array Size of Label\n",
        "print(\"Size of Training Labels :\"+str(train_labels.shape))\n",
        "\n",
        "#Print Array Size of Test Set \n",
        "print(\"Size of Test Images :\"+str(test_images.shape))\n",
        "#Print Array Size of Label\n",
        "print(\"Size of Test Labels :\"+str(test_labels.shape))\n",
        "\n",
        "#Let's See how our Outputs Look like \n",
        "print(\"Training Set Labels :\"+str(train_labels))\n",
        "#Data in the Test Set\n",
        "print(\"Test Set Labels :\"+str(test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXkwjTDqAqri",
        "outputId": "9edea1ba-0d3d-46b9-f0ac-59ace082410c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Training Images :(60000, 28, 28)\n",
            "Size of Training Labels :(60000,)\n",
            "Size of Test Images :(10000, 28, 28)\n",
            "Size of Test Labels :(10000,)\n",
            "Training Set Labels :[9 0 0 ... 3 0 5]\n",
            "Test Set Labels :[9 2 1 ... 8 1 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Pre-processing"
      ],
      "metadata": {
        "id": "HGMIcqPmBE_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bbwE7WQsAquX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The image pixel values range from 0 to 255. Let us now normalise the data range from 0 - 255 to 0 - 1 in both the Train and Test set. This Normalisation of pixels helps us by optimizing the process where the gradients are computed."
      ],
      "metadata": {
        "id": "kdmxNqJDBJRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "_yV11R4PBJYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's Print to Veryify if the Data is of the correct format.\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WJGj-n82BNg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part1 MLP"
      ],
      "metadata": {
        "id": "yHVAV-Gf9TZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining our Model\n",
        "\n",
        "Our model has three layers:\n",
        "\n",
        "- 784 input features (28 * 28)\n",
        "- 128 nodes in the hidden layer (feel free to experiment with this value)\n",
        "- 10 output nodes to denote the class\n",
        "\n",
        "We will implement this model in Keras (TensorFlow's high-level API for machine learning).\n"
      ],
      "metadata": {
        "id": "Hy_kB6BgBP0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BUW-2dCrBRLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first layer in this network, tf.keras.layers.Flatten, transforms the format of the images from a two-dimensional array (of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels). Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn; it only reformats the data.\n",
        "\n",
        "After the pixels are flattened, the network consists of a sequence of two tf.keras.layers.Dense layers. These are densely connected, or fully connected, neural layers. The first Dense layer has 128 nodes (or neurons). The second (and last) layer is a 10-node softmax layer that returns an array of 10 probability scores that sum to 1. Each node contains a score that indicates the probability that the current image belongs to one of the 10 classes.\n",
        "\n",
        "## Compile the model\n",
        "Before the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n",
        "\n",
        "- Loss function —This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n",
        "- Optimizer —This is how the model is updated based on the data it sees and its loss function.\n",
        "- Metrics —Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified."
      ],
      "metadata": {
        "id": "Bywu-xiJBVvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Saz39iwmBUrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "Training the neural network model requires the following steps:\n",
        "\n",
        "- Feed the training data to the model. In this example, the training data is in the `train_images` and `train_labels` arrays.\n",
        "- The model learns to associate images and labels.\n",
        "- You ask the model to make predictions about a test set—in this example, the `test_images` array. Verify that the predictions match the labels from the `test_labels` array.\n",
        "\n",
        "To start training, call the `model.fit` method—so called because it \"fits\" the model to the training data:"
      ],
      "metadata": {
        "id": "6UyH241hBoCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels ,epochs=5)"
      ],
      "metadata": {
        "id": "JjKendLcBnbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate accuracy\n",
        "Next, compare how the model performs on the test dataset:"
      ],
      "metadata": {
        "id": "sl846-fLByJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the Model using the Test Set\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "BLT5lOBLBwo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "Try adding more dense layers to the network above and observe change in accuracy.\n",
        "\n",
        "We get an Accuracy of 87% in the Test dataset which is less than the 89% we got during the Training phase, This problem in ML is called as Overfitting"
      ],
      "metadata": {
        "id": "O5yO4v-GB_HZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    #TODO \n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "IWDCOfTDE7Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JZ__woD4Eu3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels ,epochs=5)"
      ],
      "metadata": {
        "id": "wRhjuul-EhDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the Model using the Test Set\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "inCWCptwEib-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Excerise 2\n",
        "more deeper and wide"
      ],
      "metadata": {
        "id": "aQUOcScd6L6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    #TODO \n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "VbpI6WZu6P7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ZTCYu7Y76P_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels ,epochs=5)"
      ],
      "metadata": {
        "id": "FXbrm18m6QDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the Model using the Test Set\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "vvjr28Yb6QF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2. Implementing Image Classification using CNN's\n",
        "We will the following the same steps for Data Pre-processing as mentioned in the previous Notebook :"
      ],
      "metadata": {
        "id": "7tAbBWZS62F0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reset the jupyter\n",
        "on COLAB, select Runtime menu  >> Restart Runtime "
      ],
      "metadata": {
        "id": "GQFaxBhFDVCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Necessary Libraries\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xo0jjmPDW4k",
        "outputId": "55eeda8c-e690-440e-d28c-8e20b778b16c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's Import the Dataset\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "#Print Array Size of Training Set \n",
        "print(\"Size of Training Images :\"+str(train_images.shape))\n",
        "#Print Array Size of Label\n",
        "print(\"Size of Training Labels :\"+str(train_labels.shape))\n",
        "\n",
        "#Print Array Size of Test Set \n",
        "print(\"Size of Test Images :\"+str(test_images.shape))\n",
        "#Print Array Size of Label\n",
        "print(\"Size of Test Labels :\"+str(test_labels.shape))\n",
        "\n",
        "#Let's See how our Outputs Look like \n",
        "print(\"Training Set Labels :\"+str(train_labels))\n",
        "#Data in the Test Set\n",
        "print(\"Test Set Labels :\"+str(test_labels))\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grvK-gpW6qq0",
        "outputId": "d32e4acb-035f-48d9-9825-021ce697eb20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Training Images :(60000, 28, 28)\n",
            "Size of Training Labels :(60000,)\n",
            "Size of Test Images :(10000, 28, 28)\n",
            "Size of Test Labels :(10000,)\n",
            "Training Set Labels :[9 0 0 ... 3 0 5]\n",
            "Test Set Labels :[9 2 1 ... 8 1 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Further Data pre-processing :\n",
        "You may have noticed by now that the Training Set is of Shape `(60000,28,28)`.\n",
        "\n",
        "In CNN's, we need to feed the data in the form of a 4D Array as follows :\n",
        "\n",
        "`( Num_Images, X-dims, Y-dims, # of Channels of Image )`\n",
        "\n",
        "So, as our image is grayscale, we will reshape it to `(60000,28,28,1)` before passing it to our Architecture."
      ],
      "metadata": {
        "id": "A_chxRqF7Eum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape input data from (28, 28) to (28, 28, 1)\n",
        "w, h = 28, 28\n",
        "train_images = train_images.reshape(train_images.shape[0], w, h, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], w, h, 1)"
      ],
      "metadata": {
        "id": "G_PmjOe66qtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Convolution Layers\n",
        "Let us see how to define a Convolution Layer, MaxPooling Layer and Dropout\n",
        "\n",
        "### Convolution Layer\n",
        "We will be using the following API to define the Convolution Layer.\n",
        "\n",
        "`tf.keras.layers.Conv2D(filters, kernel_size, padding='valid', activation=None, input_shape)`\n",
        "\n",
        "Let us define the parameters in brief :\n",
        "\n",
        "Filters: The dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
        "Kernel_size: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n",
        "Padding: one of \"valid\" or \"same\" (case-insensitive).\n",
        "Activation: Activation function to use (see activations). If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
        "Refer here for the Full Documentation -> Convolutional Layers\n",
        "\n",
        "### Pooling Layer\n",
        "`tf.keras.layers.MaxPooling2D(pool_size=2)`\n",
        "\n",
        "Pool size : Size of the max pooling windows.\n",
        "Keras Documentation -> Pooling Layers\n",
        "\n",
        "### Dropout\n",
        "Dropout is an approach to regularization in neural networks which helps reducing interdependent learning amongst the neurons.\n",
        "\n",
        "Simply put, dropout refers to ignoring units (i.e. neurons) during the training phase of certain set of neurons which is chosen at random. By “ignoring”, we mean these units are not considered during a particular forward or backward pass.\n",
        "\n",
        "It is defined by the following function :\n",
        "\n",
        "`tf.keras.layers.Dropout(0.3)`\n",
        "\n",
        "Parameter : float between 0 and 1. Fraction of the input units to drop.\n",
        "Keras Documentation -> Dropout\n",
        "\n",
        "## Defining our Model and Training\n",
        "Now that we are aware of the code for building a CNN , Let us now build a 5 Layer Model :\n",
        "\n",
        "- Input Layer : ( 28 , 28 ,1 )\n",
        "   - Size of the Input Image\n",
        "- Convolution layers :\n",
        "  - First Layer : Kernel Size ( 2x2 ) and we obtain 64 layers from it.\n",
        "    - Pooling of Size ( 2 x 2) making the layer to be ( 14 x 14 x 64 )\n",
        "  - Second Layer : Kernel Size ( 2 x 2 ) and obtaining 32 layers.\n",
        "    - Pooling of Size ( 2 x 2 ) making the layer to be ( 7 x 7 x 32 )\n",
        "- Fully Connected Layers :\n",
        "  - Flatten the Convolution layers to nodes of 1567 = ( 7 7 32 )\n",
        "  - Dense Layer of 256\n",
        "- Output Layer :\n",
        "  - Densely Connected Layer with 10 classes with softmax activation\n",
        " \n",
        "\n",
        "Here , Let us now define our Model in Keras"
      ],
      "metadata": {
        "id": "sMmc9N0P7PMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "K.clear_session()\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "# model.add(tf.keras.layers.Dropout(0.3))\n",
        "#Second Convolution Layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "#Fully Connected Layer\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "jC-GEqVm6qzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the model\n",
        "Before the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n",
        "\n",
        "- Loss function —This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n",
        "- Optimizer —This is how the model is updated based on the data it sees and its loss function.\n",
        "- Metrics —Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified."
      ],
      "metadata": {
        "id": "o_mDG3uD75LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "r5a8CGRm6q2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "Training the neural network model requires the following steps:\n",
        "\n",
        "- Feed the training data to the model. In this example, the training data is in the `train_images` and `train_labels` arrays.\n",
        "- The model learns to associate images and labels.\n",
        "- You ask the model to make predictions about a test set—in this example, the `test_images` array. Verify that the predictions match the labels from the `test_labels` array.\n",
        "\n",
        "To start training, call the `model.fit` method—so called because it \"fits\" the model to the training data:"
      ],
      "metadata": {
        "id": "AKNDFTZ28GEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels,batch_size=32 ,epochs=5)"
      ],
      "metadata": {
        "id": "-E778qzl8Ch7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the Model using the Test Set\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "jt-shotq8XtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Predictions :"
      ],
      "metadata": {
        "id": "0enLZn0m8eZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making Predictions from the test_images\n",
        "\n",
        "predictions = model.predict(test_images)"
      ],
      "metadata": {
        "id": "u2Q2iDd78gDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape input data from (28, 28) to (28, 28, 1)\n",
        "w, h = 28, 28\n",
        "train_images = train_images.reshape(train_images.shape[0], w, h)\n",
        "test_images = test_images.reshape(test_images.shape[0], w, h)\n",
        "\n",
        "\n",
        "# Helper Functions to Plot Images \n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array,true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "metadata": {
        "id": "Jbycj6li8hXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first X test images, their predicted labels, and the true labels.\n",
        "# Color correct predictions in blue and incorrect predictions in red.\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions[i], test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions[i], test_labels)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KGTFc_vj8lIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "Play with different hyper-parameters ( Epoch, depth of layers , kernel size ... ) to bring down loss further"
      ],
      "metadata": {
        "id": "giK--NlrAqVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e1b4tzOl6upZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "K.clear_session()\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "# model.add(tf.keras.layers.Dropout(0.3))\n",
        "#Second Convolution Layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "#Fully Connected Layer\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "8j19PPWp6u-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NvQwziQr6vB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels,batch_size=32 ,epochs=5)"
      ],
      "metadata": {
        "id": "Lsw4paxG6vEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the Model using the Test Set\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "zOzo22Es6vH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part3. ResNet"
      ],
      "metadata": {
        "id": "QAkJhqH-65FS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Necessary Libraries\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "from IPython.display import SVG\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "Xj5B3MX_65bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image classification on types of clothes  \n",
        "\n",
        "####  Step 1: Data \n",
        "\n",
        "We will be using the **Fashion MNIST** dataset, which is a very popular introductory dataset in deep learning. This dataset contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels)."
      ],
      "metadata": {
        "id": "sABXz-lf8RLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's Import the Dataset\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "laUxgqRE7yq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining class names\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "metadata": {
        "id": "rBZLgM0970Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the Size of our Dataset\n",
        "\n",
        "# Print array size of training dataset\n",
        "print(\"Size of Training Images: \" + str(train_images.shape))\n",
        "# Print array size of labels\n",
        "print(\"Size of Training Labels: \" + str(train_labels.shape))\n",
        "\n",
        "# Print array size of test dataset\n",
        "print(\"Size of Test Images: \" + str(test_images.shape))\n",
        "# Print array size of labels\n",
        "print(\"Size of Test Labels: \" + str(test_labels.shape))\n",
        "\n",
        "# Let's see how our outputs look\n",
        "print(\"Training Set Labels: \" + str(train_labels))\n",
        "# Data in the test dataset\n",
        "print(\"Test Set Labels: \" + str(test_labels))"
      ],
      "metadata": {
        "id": "TPsat_mE70bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing \n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KxqbLqDa70eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "UD_GktmV70gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's print to verify whether the data is of the correct format.\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X6Fj6yj_755K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape input data from (28, 28) to (28, 28, 1)\n",
        "w, h = 28, 28\n",
        "train_images = train_images.reshape(train_images.shape[0], w, h, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], w, h, 1)"
      ],
      "metadata": {
        "id": "LtjP9en37576"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Residual Blocks \n",
        "\n",
        "In a residual block the activation of a layer is fast-forwarded to a deeper layer in the neural network. Residual blocks help in the flow of information from the initial layers to the final layers. This is done by the introduction of skip connections, as seen in the image below.\n",
        "\n",
        "*Let us consider $H(x)$  as an underlying mapping to be fit by a few stacked layers (not necessarily the entire net), with $x$ denoting the inputs to the first of these layers. If one hypothesizes that multiple nonlinear layers can asymptotically approximate complicated functions, then it is equivalent to hypothesize that they can asymptotically approximate the residual functions, i.e., $H(x) − x$ (assuming that the input and output are of the same dimensions).*\n",
        "\n",
        "So rather than expecting the stacked layers to approximate $H(x)$, we explicitly let these layers approximate a residual function. \n",
        "\n",
        "$F(x) = H(x) − x$. \n",
        "\n",
        "The original function thus becomes $F(x)+x$.\n",
        "\n",
        "*Although both models should be able to approximate the desired functions asymptotically, the ease of learning might be different. This reformulation is motivated by the counterintuitive phenomena about the degradation problem. As we discussed above, if the added layers can be constructed as identity mappings, a deeper model should have training error no greater than its shallow counterpart.*"
      ],
      "metadata": {
        "id": "Ce_b_X2f9fi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building our Residual Network"
      ],
      "metadata": {
        "id": "87JHwQMj7uxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Identity Block\n",
        "\n",
        "In the *identity block* we have a skip connection with no change in input, paired with a standard set of convolutional layers. "
      ],
      "metadata": {
        "id": "szPXK_V58Crw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \n",
        "    # Defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # A path is a block of conv followed by batch normalization and activation\n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "metadata": {
        "id": "aTEvtglf7Owg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convolution Block\n",
        "\n",
        "The convolution block is very similar to the identity block, but there is a convolutional layer in the skip-connection path just to change the dimension such that the dimension of the input and output matches."
      ],
      "metadata": {
        "id": "625f3wyQ8Dfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "\n",
        "    # Defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "D5WrCXSW7O6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qSEl9vkz8JqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet(input_shape = (28, 28, 1), classes = 10):\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(shape=input_shape)\n",
        "\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # AVGPOOL\n",
        "    X = AveragePooling2D(pool_size=(2,2), padding='same')(X)\n",
        "\n",
        "    # Output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "4Pr7jxaZ7O_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()\n",
        "model = ResNet(input_shape = (28, 28, 1), classes = 10)"
      ],
      "metadata": {
        "id": "LLQDG-pD7PCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "leHrCjec7PFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs = 5, batch_size = 32)"
      ],
      "metadata": {
        "id": "owVLDLlW8W-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model using the test set\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "pG0VxQQi8XBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions from the test_images\n",
        "\n",
        "predictions = model.predict(test_images)"
      ],
      "metadata": {
        "id": "eIczRANJ8XED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape input data from (28, 28) to (28, 28, 1)\n",
        "w, h = 28, 28\n",
        "train_images = train_images.reshape(train_images.shape[0], w, h)\n",
        "test_images = test_images.reshape(test_images.shape[0], w, h)\n",
        "\n",
        "# Helper functions to plot images \n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "metadata": {
        "id": "oM_1vMWY8eZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first X test images, their predicted labels, and the true labels.\n",
        "# Color correct predictions in blue and incorrect predictions in red.\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions[i], test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions[i], test_labels)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mG9ImTlM8ebw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "Running all of our models for five epochs, here is a table comparing them (your results may be slightly different):\n",
        "\n",
        "|  Model                                   | Train Accuracy | Train Loss | Test Accuracy | Test Loss |\n",
        "|------------------------------------------|----------------|------------|---------------|-----------|\n",
        "| Fully connected network - After 5 Epochs |         0.8923 |     0.2935 |        0.8731 |    0.2432 |\n",
        "| Convolutional network - After 5 Epochs   |         0.8860 |     0.3094 |        0.9048 |    0.1954 |      \n",
        "| Residual network - After 5 Epochs        |         0.9064 |     0.2610 |        0.8713 |    0.3398 |\n",
        "\n",
        "From the table above we can conclude that for this example CNNs are efficient compared to other machine learning algorithms when it comes to image processing tasks.\n",
        "\n",
        "Congratulations on making it this far. Now that you are introduced to machine learning and deep learning, you can get started on the domain specific problem accessible through the home page."
      ],
      "metadata": {
        "id": "hMuRc5o28knv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Licensing\n",
        "This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0)."
      ],
      "metadata": {
        "id": "qH1a2WTzGJzr"
      }
    }
  ]
}